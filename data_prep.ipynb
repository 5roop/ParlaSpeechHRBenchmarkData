{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from shutil import copy\n",
    "\n",
    "to_copy = [\n",
    " '012_train.csv',\n",
    " '006_age_train.csv',\n",
    " '001_gender_test.csv',\n",
    " '006_age_dev.csv',\n",
    " '001_gender_train.csv',\n",
    " '001_gender_dev.csv',\n",
    " '012_dev.csv',\n",
    " '003_speaker_id.csv',\n",
    " '012_test.csv',\n",
    " '006_age_test.csv',\n",
    " ]\n",
    "for file in to_copy:\n",
    "    copy(\"../task11/\" + file, \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "dev = pd.read_csv(\"001_gender_dev.csv\")\n",
    "train = pd.read_csv(\"001_gender_train.csv\")\n",
    "test = pd.read_csv(\"001_gender_test.csv\")\n",
    "def get_filename_from_path(s:str)->str:\n",
    "    return Path(s).name\n",
    "\n",
    "dev[\"file\"] = dev.path.apply(get_filename_from_path)\n",
    "test[\"file\"] = test.path.apply(get_filename_from_path)\n",
    "train[\"file\"] = train.path.apply(get_filename_from_path)\n",
    "\n",
    "dev[\"split\"] = \"dev\"\n",
    "test[\"split\"] = \"test\"\n",
    "train[\"split\"] = \"train\"\n",
    "\n",
    "dev = dev[[\"file\", \"Speaker_gender\", \"split\"]]\n",
    "test = test[[\"file\", \"Speaker_gender\", \"split\"]]\n",
    "train = train[[\"file\", \"Speaker_gender\", \"split\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df = pd.concat([train, dev, test], ignore_index=True)\n",
    "gender_df.columns = [c.lower() for c in gender_df.columns]\n",
    "gender_df[\"speaker_gender\"] = gender_df.speaker_gender.str.lower()\n",
    "gender_df.to_json(\"gender.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speaker identification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = pd.read_csv(\"003_speaker_id.csv\")\n",
    "sp[\"path\"] = sp.path.apply(lambda s: \"seg.\" + s )\n",
    "sp = sp.rename(columns={\"path\": \"file\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.columns = [c.lower() for c in sp.columns]\n",
    "sp.to_json(\"speaker_id.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = pd.read_csv(\"006_age_dev.csv\")\n",
    "train = pd.read_csv(\"006_age_train.csv\")\n",
    "test = pd.read_csv(\"006_age_test.csv\")\n",
    "\n",
    "dev[\"split\"] = \"dev\"\n",
    "test[\"split\"] = \"test\"\n",
    "train[\"split\"] = \"train\"\n",
    "\n",
    "dev[\"file\"] = dev.path.apply(get_filename_from_path)\n",
    "test[\"file\"] = test.path.apply(get_filename_from_path)\n",
    "train[\"file\"] = train.path.apply(get_filename_from_path)\n",
    "\n",
    "\n",
    "dev = dev[[\"file\", \"Speaker_age_group\", \"split\"]]\n",
    "test = test[[\"file\", \"Speaker_age_group\", \"split\"]]\n",
    "train = train[[\"file\", \"Speaker_age_group\", \"split\"]]\n",
    "\n",
    "age_df = pd.concat([train, dev, test], ignore_index=True)\n",
    "age_df.columns = [c.lower() for c in age_df.columns]\n",
    "age_df.to_json(\"age.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = pd.read_csv(\"012_dev.csv\")\n",
    "train = pd.read_csv(\"012_train.csv\")\n",
    "test = pd.read_csv(\"012_test.csv\")\n",
    "\n",
    "dev[\"split\"] = \"dev\"\n",
    "test[\"split\"] = \"test\"\n",
    "train[\"split\"] = \"train\"\n",
    "\n",
    "dev[\"file\"] = dev.path.apply(get_filename_from_path)\n",
    "test[\"file\"] = test.path.apply(get_filename_from_path)\n",
    "train[\"file\"] = train.path.apply(get_filename_from_path)\n",
    "\n",
    "\n",
    "dev = dev[[\"file\", \"Party_status\", \"split\"]]\n",
    "test = test[[\"file\", \"Party_status\", \"split\"]]\n",
    "train = train[[\"file\", \"Party_status\", \"split\"]]\n",
    "\n",
    "power_df = pd.concat([train, dev, test], ignore_index=True)\n",
    "power_df.columns = [c.lower() for c in power_df.columns]\n",
    "power_df = power_df.rename(columns={\"party_status\": \"power_status\"})\n",
    "power_df[\"power_status\"] = power_df.power_status.str.lower()\n",
    "power_df.to_json(\"power_status.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `finally:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in to_copy:\n",
    "    Path(file).unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d30c88cb7145d662123f76f8c64609bc18e52940d2861adec2407b68f2e334f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
